{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the different Polymath projects and their evolution\n",
    "\n",
    "## 1. Preparing the data\n",
    "We start by setting up, loading the urls of the discussions, and putting everything in a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickallo/anaconda/envs/python3/lib/python3.5/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from concurrent import futures\n",
    "from itertools import chain, product\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from urllib.parse import urlparse\n",
    "import datetime\n",
    "\n",
    "from comment_thread import *\n",
    "from author_network import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note to self:** Keep in mind that cashing requests leads to missing new content (at least in PM10)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IS_RESEARCH = {'pm 1': [False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, False, False, False, False, False],\n",
    "               'mini_pm 1': [True, True, False],\n",
    "               'pm 3' : [False, False, False, False, False, False, False, True, True, True, True],\n",
    "               'pm 5' : [False, False, False, False, False, False,\n",
    "                         True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True],\n",
    "               'mini_pm 2': [False, False, False, False, True],\n",
    "               'pm 6': [True, False],\n",
    "               'mini_pm 3': [False, False, True],\n",
    "               'mini_pm 4': [False, False, False, True, True],\n",
    "               'pm 8' : [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
    "                        False, False, False, False, False,\n",
    "                        True, True, True, True, True, True, True,\n",
    "                        False,\n",
    "                        True, True, True, True,\n",
    "                        False, False, False],\n",
    "              'pm 9' : [False, True, True]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check csv-files for presence of quotes that may be unnecessary**\n",
    "\n",
    "The function `process_polymath` takes a referes to a Polymath or Mini Polymath project as an argument (format: \"pm i\" or \"mini_pm i\") and returns a `pandas.DataFrame` with each row a discussion-thread and the following columns:\n",
    "+ title: title of the thread.\n",
    "+ url: url of the thread\n",
    "+ blog: the blog where the thread takes place\n",
    "+ research: whether it is a research-thread\n",
    "+ number of comments: the number of comments in the current thread\n",
    "+ number of comments (accumulated): the number of comments in the project up to and including current thread (`cumsum` of previous, but should coincide with result from accumulated mthread)\n",
    "+ thread: a `CommentThread` object for the current thread\n",
    "+ mthread (single): a `MultiCommentThread` object based on the current thread\n",
    "+ mthread (accumulated): a `MultiCommentThread` object based on all threads up to and including the current thread\n",
    "+ network: a `AuthorNetwork` object based on the accumulated mthread\n",
    "+ r_mthread (accumulated): a `MultiCommentThread` object based on all research threads up to and including the current thread (`NaN` if current thread is not research)\n",
    "+ r_network: a `AuthorNetwork` object based on the accumulated research mthread\n",
    "+ d_mthread (accumulated): a `MultiCommentThread` object based on all non-research threads up to and including the current thread (`NaN` if current thread is  research)\n",
    "+ d_network: a `AuthorNetwork` object based on the accumulated non-research mthread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_polymath(project, split=False):\n",
    "    message = \"Polymath {}\".format(project.split(\" \")[-1]) if project.startswith(\"pm\") else \"Mini Polymath {}\".format(project[-1])\n",
    "    SETTINGS = {\n",
    "    'msg' : message,\n",
    "    'filename' : message.replace(\" \", \"\"),\n",
    "    'source' : project.replace(\" \", \"\"),\n",
    "    'urls' : [],\n",
    "    'type' : '',\n",
    "    'parser' : 'html5lib',\n",
    "    'cmap' : plt.cm.Paired, # not a string, this is an object\n",
    "    'vmin' : 1,\n",
    "    'vmax' : 100}\n",
    "    \n",
    "    with open(\"DATA/\" + SETTINGS['source'] + \".csv\", \"r\") as input:\n",
    "        pm_frame = pd.read_csv(input, index_col=\"Ord\")\n",
    "    \n",
    "    #with open(\"DATA/\"+ SETTINGS['source'] + \".txt\", \"r\") as input:\n",
    "    #    soup = BeautifulSoup(input.readline(), \"html.parser\")\n",
    "    \n",
    "    #items = soup.find(\"ul\").find_all(\"li\")\n",
    "    #urls, titles = zip(*[(item.get(\"href\"), item.text) for item in soup.find_all(\"a\")])\n",
    "    \n",
    "    #research = IS_RESEARCH[project] if project in IS_RESEARCH else [\"discussion\" not in title.lower() for title in titles]\n",
    "        \n",
    "    #pm_frame = DataFrame({\n",
    "    #    'url': urls,\n",
    "    #    'title' : titles,\n",
    "    #    'blog' : [urlparse(url).netloc.split('.')[0].title() for url in urls],\n",
    "    #    'research' : research},\n",
    "    #    columns = ['title', 'url', 'blog', 'research'])\n",
    "            \n",
    "    pm_frame['blog'] = pm_frame['url'].apply(lambda url: urlparse(url).netloc.split('.')[0].title())\n",
    "    with futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            pm_frame['thread'] = list(executor.map(\n",
    "                    lambda url, blog: THREAD_TYPES[blog](url),\n",
    "                    pm_frame['url'], pm_frame['blog']))\n",
    "    #pm_frame['thread'] = [THREAD_TYPES[blog](url) for (url, blog) in zip(pm_frame['url'], pm_frame['blog'])]\n",
    "    pm_frame['number of comments'] = pm_frame['thread'].apply(lambda x: len(x.node_name.keys()))\n",
    "    pm_frame['number of comments (accumulated)'] = pm_frame['number of comments'].cumsum()\n",
    "        \n",
    "    indices = pm_frame.index\n",
    "    threads = pm_frame.thread\n",
    "    pm_frame['mthread (single)'] = pm_frame['thread'].apply(MultiCommentThread)\n",
    "    pm_frame['mthread (accumulated)'] = Series([MultiCommentThread(*threads[0:i+1]) for i in indices],\n",
    "                                               index=indices)\n",
    "    pm_frame['network'] = pm_frame['mthread (accumulated)'].apply(AuthorNetwork)\n",
    "    \n",
    "    if split:\n",
    "        r_indices = pm_frame[pm_frame['research']].index\n",
    "        d_indices = pm_frame[~pm_frame['research']].index\n",
    "        r_threads = pm_frame[pm_frame['research']].thread\n",
    "        d_threads = pm_frame[~pm_frame['research']].thread\n",
    "        pm_frame['r_mthread (accumulated)'] = Series([MultiCommentThread(*r_threads[0:i+1]) for i in r_indices],\n",
    "                                                 index=r_indices)\n",
    "        pm_frame['d_mthread (accumulated)'] = Series([MultiCommentThread(*d_threads[0:i+1]) for i in d_indices],\n",
    "                                                 index=d_indices)\n",
    "        pm_frame['r_network'] = pm_frame[pm_frame['research']]['r_mthread (accumulated)'].apply(AuthorNetwork)\n",
    "        pm_frame['d_network'] = pm_frame[~pm_frame['research']]['d_mthread (accumulated)'].apply(AuthorNetwork)\n",
    "        pm_frame = pm_frame.reindex_axis(['title', 'url', 'blog', 'research',\n",
    "                                          'number of comments', 'number of comments (accumulated)',\n",
    "                                          'thread', 'mthread (single)',\n",
    "                                          'mthread (accumulated)', 'network',\n",
    "                                          'r_mthread (accumulated)', 'r_network',\n",
    "                                          'd_mthread (accumulated)', 'd_network'],\n",
    "                                         axis=1)\n",
    "    else:\n",
    "        pm_frame = pm_frame.reindex_axis(['title', 'url', 'blog', 'research', 'number of comments',\n",
    "                                      'thread', 'mthread (single)',\n",
    "                                      'mthread (accumulated)', 'network'],\n",
    "                                     axis=1)\n",
    "\n",
    "    pm_frame.index = pd.MultiIndex.from_tuples([(SETTINGS['msg'], i) for i in indices],\n",
    "                                               names=['Project', 'Ord'])\n",
    "    \n",
    "    return pm_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrickallo/anaconda/envs/python3/lib/python3.5/multiprocessing/queues.py\", line 241, in _feed\n",
      "    obj = ForkingPickler.dumps(obj)\n",
      "  File \"/Users/patrickallo/anaconda/envs/python3/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'process_polymath.<locals>.<lambda>'\n"
     ]
    }
   ],
   "source": [
    "PM1_FRAME = process_polymath(\"pm 1\", split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 4 workers: 1 loop, best of 3: 1min 10s per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM2_FRAME = process_polymath(\"pm 2\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mPM1_FRAME = process_polymath(\"mini_pm 1\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM3_FRAME = process_polymath(\"pm 3\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM4_FRAME = process_polymath(\"pm 4\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM5_FRAME = process_polymath(\"pm 5\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mPM2_FRAME = process_polymath(\"mini_pm 2\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM6_FRAME = process_polymath(\"pm 6\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mPM3_FRAME = process_polymath(\"mini_pm 3\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mPM4_FRAME = process_polymath(\"mini_pm 4\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM7_FRAME = process_polymath(\"pm 7\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM8_FRAME = process_polymath(\"pm 8\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM9_FRAME = process_polymath(\"pm 9\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM10_FRAME = process_polymath(\"pm 10\", split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM11_FRAME = process_polymath(\"pm 11\", split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all Polymath and Mini Polymath frames is created, and then used to create two large `pandas.DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POLYMATHS = [PM1_FRAME, PM2_FRAME, PM3_FRAME, PM4_FRAME, PM5_FRAME, PM6_FRAME, PM7_FRAME, PM8_FRAME, PM9_FRAME, PM10_FRAME, PM11_FRAME]\n",
    "MINIPOLYMATHS = [mPM1_FRAME, mPM2_FRAME, mPM3_FRAME, mPM4_FRAME]\n",
    "COL_ORDER = PM1_FRAME.columns.tolist()\n",
    "PM_FRAME = pd.concat(POLYMATHS)[COL_ORDER]\n",
    "mPM_FRAME = pd.concat(MINIPOLYMATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional columns with sets of authors for threads and accumulated mthreads are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM_FRAME['authors'] = PM_FRAME['thread'].apply(lambda thread: thread.authors)\n",
    "PM_FRAME['authors (accumulated)'] = PM_FRAME['network'].apply(lambda network: set(network.author_frame.index))\n",
    "mPM_FRAME['authors'] = mPM_FRAME['thread'].apply(lambda thread: thread.authors)\n",
    "mPM_FRAME['authors (accumulated)'] = mPM_FRAME['network'].apply(lambda network: set(network.author_frame.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets of all PM-authors and all Mini-PM-authors are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALL_AUTHORS = set.union(*PM_FRAME['authors'].tolist())\n",
    "ALL_MINI_AUTHORS = set.union(*mPM_FRAME['authors'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check (using string-similarity) for authors that may appear under different names. The outcome of this has been used to further populate `author_convert.yaml` which is used during the parsing of the threads. What remains is not sufficient to warrant further additions to author_convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "for (str1, str2) in combinations(ALL_AUTHORS, 2):\n",
    "    if SequenceMatcher(None, str1, str2).ratio() > .8:\n",
    "        print(str1, str2)\n",
    "        \n",
    "for (str1, str2) in combinations(ALL_MINI_AUTHORS, 2):\n",
    "    if SequenceMatcher(None, str1, str2).ratio() > .8:\n",
    "        print(str1, str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating additional functions\n",
    "### 2.1. Wrapping object-methods into functions\n",
    "We define functions that take a project as argument call a method form the appropriate object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_project_at(project, stage):\n",
    "    return mPM_FRAME.loc[project].iloc[stage] if project.startswith(\"Mini\") else PM_FRAME.loc[project].iloc[stage]\n",
    "\n",
    "def draw_network(project, stage=-1):\n",
    "    \"\"\"Wrapper function for author_network.draw_graph.\n",
    "    Plots the interaction-network between the commenters in project.\"\"\"\n",
    "    get_project_at(project, stage)['network'].draw_graph(project=project)\n",
    "    \n",
    "def draw_centre(project, stage=-1, skips=10, zoom=1):\n",
    "    \"\"\"Wrapper function for author_network.draw_centre_discussion\"\"\"\n",
    "    get_project_at(project, stage)['network'].draw_centre_discussion(skips=skips, zoom=zoom)\n",
    "\n",
    "def plot_activity_pie(project, stage=-1):\n",
    "    \"\"\"Wrapper function for author_network.plot_author_activity_pie\n",
    "    Plots pie-chart of comment_activity of commenters is project.\"\"\"\n",
    "    get_project_at(project, stage)['network'].plot_author_activity_pie(project=project)\n",
    "    \n",
    "def plot_activity_bar(project, stage=-1):\n",
    "    \"\"\"Wrapper function for author_network.plot_activity_bar\n",
    "    Plots bar-chart of comment_activity of commenters in project\"\"\"\n",
    "    get_project_at(project, stage)['network'].plot_author_activity_bar(project=project)\n",
    "\n",
    "def plot_degree_centrality(project, stage=-1):\n",
    "    \"\"\"Wrapper function for author_network.plot_degree_centrality\n",
    "    Plots line-chart of degree-centrality of commenters in project\"\"\"\n",
    "    get_project_at(project, stage)['network'].plot_degree_centrality(project=project)\n",
    "\n",
    "def plot_activity_degree(project, stage=-1):\n",
    "    \"\"\"Wrapper function for author_network.plit_activity_degree\n",
    "    Plots superposition of bar-chart of comment-activity and line-chart of degree-centrality\"\"\"\n",
    "    get_project_at(project, stage)['network'].plot_activity_degree(project=project)\n",
    "\n",
    "def plot_discussion(project, intervals=10, first=SETTINGS['first_date'], last=SETTINGS['last_date'], stage=-1):\n",
    "    \"\"\"Wrapper function for mthread.draw_graph\n",
    "    Plots structure of discussion in project\"\"\"\n",
    "    get_project_at(project, stage)['mthread (accumulated)'].draw_graph(intervals=intervals,\n",
    "                                                                       first=first,\n",
    "                                                                       last=last,\n",
    "                                                                       project=project)\n",
    "\n",
    "def plot_activity(project, intervals=1, first=SETTINGS['first_date'], last=SETTINGS['last_date'],\n",
    "                  activity='thread', stage=-1):\n",
    "    \"\"\"Wrapper function for mthread.plot_activity\n",
    "    Plots thread or author activity over time for project\"\"\"\n",
    "    get_project_at(project, stage)['mthread (accumulated)'].plot_activity(activity, intervals=intervals,\n",
    "                                                                          first=first,\n",
    "                                                                          last=last,\n",
    "                                                                          project=project)\n",
    "\n",
    "def plot_growth(project, last= datetime.today(), stage=-1):\n",
    "    \"\"\"Wrapper function for mthread.plot_growth\n",
    "    Plots growth in comments in discussion\"\"\"\n",
    "    get_project_at(project, stage)['mthread (accumulated)'].plot_growth(project=project, last=last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating additional functionality to show community engagement over time\n",
    "We start with a small auxiliary function that returns the last row for each project from a large DateFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_last(lst_of_frames):\n",
    "    if lst_of_frames == POLYMATHS:\n",
    "        source = PM_FRAME\n",
    "        positions = np.array([frame.index.levels[1][-1] for frame in lst_of_frames]).cumsum() + np.arange(len(POLYMATHS))\n",
    "    elif lst_of_frames == MINIPOLYMATHS:\n",
    "        source = mPM_FRAME\n",
    "        positions = np.array([frame.index.levels[1][-1] for frame in lst_of_frames]).cumsum() + np.arange(len(MINIPOLYMATHS))\n",
    "    else:\n",
    "        raise ValueError(\"Need either POLYMATHS or MINIPOLYMATHS\")\n",
    "    source.index = source.index.swaplevel(0,1)\n",
    "    data = source.iloc[positions]\n",
    "    source.index = source.index.swaplevel(1,0)\n",
    "    data.index = data.index.droplevel()\n",
    "    return data, positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Four complementary functions are defined which visualise how *community engagement* (how many participants, how diverse, who leaves, who joins) in projects or groups of projects evolves over time.\n",
    "\n",
    "The function `plot_thread_engagement` takes a project as argument, and shows four types of data for each thread in bar-plot:\n",
    "1. y-axis: the average number of comments per participant (a measure of how diverse each thread is)\n",
    "2. width of each bar: the number of comments\n",
    "3. bar-color: the type of thread\n",
    "4. text above each bar included in the optional kwarg `sel`: number of comments and number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_thread_engagement(project, compress=1, sel=[]):\n",
    "    data = mPM_FRAME.loc[project] if project.startswith(\"Mini\") else PM_FRAME.loc[project]\n",
    "    authors = data['authors'].apply(len)\n",
    "    engagement = authors / data['number of comments']\n",
    "    df = DataFrame({'research threads': engagement[data['research']],\n",
    "                    'discussion threads': engagement[~data['research']]},\n",
    "                   #columns = ['research threads', 'discussion threads'],\n",
    "                   index=data.index)\n",
    "    sizes = (data['number of comments'] / compress).tolist()\n",
    "    df.index.name = \"Threads\"\n",
    "    matplotlib.style.use('seaborn-notebook')\n",
    "    fig = plt.figure()\n",
    "    axes = df.plot(kind='bar', color=['lightsteelblue', 'steelblue'],\n",
    "                   title = \"Community engagement in {}\".format(project))\n",
    "    axes.set_ylabel('average number of comments per participant')\n",
    "    axes.set_yticklabels([round(1/i, 2) for i in axes.get_yticks()])\n",
    "    axes.set_xticklabels(data['title'].apply(lambda x: x[:40]), rotation=90, fontsize='small')\n",
    "    for container in axes.containers:\n",
    "        for i, child in enumerate(container.get_children()):\n",
    "            child.set_x(df.index[i] - sizes[i]/2)\n",
    "            plt.setp(child, width=sizes[i])\n",
    "    for i in engagement.index:\n",
    "            if i in sel:\n",
    "                axes.text(engagement.index[i] + .2, engagement[i],\n",
    "                          \"{} comments\\n {} commenters\".format(data['number of comments'][i], authors[i]),\n",
    "                          ha=\"center\", va=\"bottom\", fontsize='small')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `plot_thread_evolution` takes a project as argument and shows two plots:\n",
    "1. The bar-plot `thread_engagement` described above\n",
    "2. The evolution of the number of participants in each thread (active, joined, left) as an area-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_thread_evolution(project, compress=1, sel=[], sharex=True):\n",
    "    # data for evolution\n",
    "    data = mPM_FRAME.loc[project] if project.startswith(\"Mini\") else PM_FRAME.loc[project]\n",
    "    added = (data['authors'] - data['authors'].shift(1)).apply(lambda x: 0 if isinstance(x, float) else len(x))\n",
    "    removed = (data['authors'].shift(1) - data['authors']).apply(lambda x: 0 if isinstance(x, float) else - len(x))\n",
    "    size = data['authors'].apply(len) - added\n",
    "    df1 = DataFrame({'joined' : added, 'left' : removed, 'current': size},\n",
    "                   columns=[\"joined\", \"current\", \"left\"], index=data.index)\n",
    "    df1.index.name = \"Threads\"\n",
    "    # data for engagement\n",
    "    authors = data['authors'].apply(len)\n",
    "    engagement = authors / data['number of comments']\n",
    "    df2 = DataFrame({'research threads': engagement[data['research']],\n",
    "                    'discussion threads': engagement[~data['research']]},\n",
    "                   #columns = ['research threads', 'discussion threads'],\n",
    "                   index=data.index)\n",
    "    sizes = (data['number of comments'] / compress).tolist()\n",
    "    df2.index.name = \"Threads\"\n",
    "    # setting up plot\n",
    "    matplotlib.style.use('seaborn-talk')\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 6), squeeze=False, sharex=sharex)\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    # plot bottom\n",
    "    df1.plot(kind=\"area\", ax = axes[1][0], title=\"\",\n",
    "            color=['sage', 'lightgrey', 'indianred'], stacked=True)\n",
    "    axes[1][0].set_xticks(df1.index)\n",
    "    axes[1][0].set_xticklabels(data['title'], rotation=90, fontsize='small')\n",
    "    axes[1][0].set_xlabel(\"\")\n",
    "    axes[1][0].set_ylabel('active commenters')\n",
    "    # plot top\n",
    "    df2.plot(kind='bar', ax = axes[0][0], color=['lightsteelblue', 'steelblue'],\n",
    "                   title = \"Community engagement in {}\".format(project))\n",
    "    axes[0][0].set_ylabel('comments per participant')\n",
    "    axes[0][0].set_yticklabels([round(1/i, 2) for i in axes[0][0].get_yticks()])\n",
    "    axes[0][0].yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "    axes[0][0].set_xticklabels(df2.index, fontsize='small')\n",
    "    axes[0][0].set_xlabel(\"\")\n",
    "    for container in axes[0][0].containers:\n",
    "        for i, child in enumerate(container.get_children()):\n",
    "            child.set_x(df2.index[i] - sizes[i]/2)\n",
    "            plt.setp(child, width=sizes[i])\n",
    "    for i in engagement.index:\n",
    "            if i in sel:\n",
    "                axes[0][0].text(engagement.index[i] + .2, engagement[i],\n",
    "                          \"{} comments\\n {} commenters\".format(data['number of comments'][i], authors[i]),\n",
    "                          ha=\"center\", va=\"bottom\", fontsize='small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `plot_community_evolution` can both take a project, and a group of projects (\"Polymath\" of \"MiniPolymath\") as an argument, and shows the evolution of the number of participants per thread or per project in the same manner as the area-plot in `plot_thread_evolution`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_community_evolution(project):\n",
    "    if isinstance(project.split()[-1], int):\n",
    "        as_threads = True\n",
    "        data = mPM_FRAME.loc[project] if project.startswith(\"Mini\") else PM_FRAME.loc[project]\n",
    "        added = (data['authors'] - data['authors'].shift(1)).apply(lambda x: 0 if isinstance(x, float) else len(x))\n",
    "        removed = (data['authors'].shift(1) - data['authors']).apply(lambda x: 0 if isinstance(x, float) else - len(x))\n",
    "        size = data['authors'].apply(len) - added\n",
    "        df = DataFrame({'joined' : added, 'left' : removed, 'current': size},\n",
    "                       columns=[\"joined\", \"current\", \"left\"], index=data.index)\n",
    "        df.index.name = \"Threads\"\n",
    "    else:\n",
    "        as_threads = False\n",
    "        if project.startswith(\"Mini\"):\n",
    "            data, positions = get_last(MINIPOLYMATHS)\n",
    "        elif project.startswith(\"Poly\"):\n",
    "            data, positions = get_last(POLYMATHS)\n",
    "        else:\n",
    "            raise ValueError(\"Need either Polymath or Mini Polymath\")\n",
    "        added = (data['authors (accumulated)'] - data['authors (accumulated)'].shift(1)).apply(lambda x: 0 if isinstance(x, float) else len(x))\n",
    "        removed = (data['authors (accumulated)'].shift(1) - data['authors (accumulated)']).apply(lambda x: 0 if isinstance(x, float) else - len(x))\n",
    "        size = data['authors (accumulated)'].apply(len) - added\n",
    "        df = DataFrame({'joined' : added, 'left' : removed, 'current': size},\n",
    "                       columns=[\"joined\", \"current\", \"left\"])\n",
    "        df.index = list(range(1, len(positions) + 1))\n",
    "    \n",
    "    matplotlib.style.use('seaborn-notebook')\n",
    "    fig = plt.figure()\n",
    "    axes = df.plot(kind=\"area\", title=\"Community Evolution in {}\".format(project),\n",
    "            color=['sage', 'lightgrey', 'indianred'], stacked=True)\n",
    "    axes.set_xticks(df.index)\n",
    "    if as_threads:\n",
    "        axes.set_xticklabels(data['title'], rotation=90, fontsize='small')\n",
    "    else:\n",
    "        xlabels = sorted(data.index, key=lambda x: int(x.split()[-1]))\n",
    "        axes.set_xticklabels(xlabels, rotation=90, fontsize='small')\n",
    "    axes.set_ylabel('number of active commenters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `plot_participation_evolution` can both take a project, and a group of projects (\"Polymath\" of \"MiniPolymath\") as an argument, and shows for each participant that took part in at least `n` projects/threads the projects/threads (s)he participated in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_participation_evolution(project, n=2, skip_anon=True):\n",
    "    if project.split()[-1]in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']:\n",
    "        print(\"process threads\")\n",
    "        as_threads = True\n",
    "        if project.startswith(\"Mini\"):\n",
    "            data = mPM_FRAME.loc[project]\n",
    "        elif project.startswith(\"Poly\"):\n",
    "            data = PM_FRAME.loc[project]\n",
    "        else:\n",
    "            raise ValueError(\"Need either Polymath or Mini Polymath project\")\n",
    "        all_authors = data.iloc[-1]['authors (accumulated)']\n",
    "        data = data['authors']\n",
    "        title = \"Participation per thread in \" + project\n",
    "    else:\n",
    "        as_threads = False\n",
    "        if project.startswith(\"Mini\"):\n",
    "            data, positions = get_last(MINIPOLYMATHS)\n",
    "            all_authors = list(ALL_MINI_AUTHORS)\n",
    "            title = \"Participation per project in Mini Polymath\"\n",
    "        elif project.startswith(\"Poly\"):\n",
    "            data, positions = get_last(POLYMATHS)\n",
    "            all_authors = list(ALL_AUTHORS)\n",
    "            title = \"Participation per project in Polymath\"\n",
    "        else:\n",
    "            raise ValueError(\"Need either Polymath or Mini Polymath\")\n",
    "        data = data['authors (accumulated)']\n",
    "    indices = data.index.tolist()\n",
    "    author_project = DataFrame(index=all_authors)\n",
    "    for ind in indices:\n",
    "        author_project[ind] = np.zeros_like(author_project.index, dtype=bool)\n",
    "        for author in data[ind]:\n",
    "            author_project[ind][author] = True\n",
    "    author_project = author_project.sort_values(by=indices, ascending=False)\n",
    "    author_project = author_project.drop(\"Anonymous\") if skip_anon else author_project\n",
    "    select = author_project.sum(axis=1) >= n\n",
    "    matplotlib.style.use('seaborn-notebook')\n",
    "    factor = 30 - len(indices) if len(indices) <= 30 else 40 - len(indices)\n",
    "    colors = [plt.cm.Set1(factor*i) for i in range(len(indices))]\n",
    "    author_project.loc[select].plot(kind=\"bar\", stacked=True, color=colors,\n",
    "                                    title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarise_project(project):\n",
    "    data = PM_FRAME.loc[project][['authors', 'number of comments']]\n",
    "    data['author count'] = data['authors'].apply(lambda set: len(set))\n",
    "    return data[['author count', 'number of comments']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. General comparisons\n",
    "### 3.1 Sizes of project\n",
    "\n",
    "We start by just looking at the number of comments for the whole of Polymath and the whole of Mini Polymath\n",
    "\n",
    "**does it make sense to plot this as well, and split up between research and discussion?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then look at the number of participats and number of comments per project (and split up between research and discussion threads for the participants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "PROJECTS_TO_C = [\"Polymath {}\".format(i) for i in range(1, 11)]\n",
    "PARTICIPANTS = Series([PM_FRAME.loc[project]['authors (accumulated)'].iloc[-1] for\n",
    "                project in PROJECTS_TO_C], index=PROJECTS_TO_C)\n",
    "R_NETWORKS = Series([PM_FRAME.loc[project]['r_network'].dropna().iloc[-1] for project in PROJECTS_TO_C],\n",
    "                    index=PROJECTS_TO_C)\n",
    "WITH_D = [project for project in PROJECTS_TO_C if not PM_FRAME.loc[project]['research'].all()]\n",
    "D_NETWORKS = Series([PM_FRAME.loc[project]['d_network'].dropna().iloc[-1] for project in WITH_D],\n",
    "                    index=WITH_D)\n",
    "R_PARTICIPANTS = R_NETWORKS.apply(lambda network: set(network.author_frame.index))\n",
    "D_PARTICIPANTS = D_NETWORKS.apply(lambda network: set(network.author_frame.index))\n",
    "COMMENTS = Series([PM_FRAME.loc[project]['number of comments (accumulated)'].iloc[-1] for\n",
    "                project in PROJECTS_TO_C], index=PROJECTS_TO_C)\n",
    "\n",
    "df = DataFrame({'all threads': PARTICIPANTS, 'research threads': R_PARTICIPANTS, 'discussion threads': D_PARTICIPANTS},\n",
    "              index=PROJECTS_TO_C)\n",
    "df['authors only active in research threads'] = df['research threads'] - df['discussion threads']\n",
    "df['authors only active in \"discussion\" threads'] = df['discussion threads'] - df['research threads']\n",
    "df['authors active in both types of threads'] = df['all threads'] - df['authors only active in research threads'] - df['authors only active in \"discussion\" threads']\n",
    "for project in PROJECTS_TO_C:\n",
    "    if pd.isnull(df.loc[project]['authors only active in research threads']):\n",
    "        df.loc[project]['authors only active in research threads'] = df.loc[project]['all threads']\n",
    "data = df[['authors only active in research threads', 'authors only active in \"discussion\" threads', 'authors active in both types of threads']]\n",
    "data = data.applymap(lambda set: len(set) if pd.notnull(set) else 0)\n",
    "matplotlib.style.use('seaborn-notebook')\n",
    "axes = data.plot(kind='bar', stacked=True, color=['steelblue', 'lightsteelblue', 'lightgrey'],\n",
    "          title=\"Number of participants per thread-type in each Polymath project\\n Number of comments per project\")\n",
    "axes.set_ylabel(\"Number of participants\")\n",
    "data2 = np.sqrt(COMMENTS)\n",
    "axes2 = axes.twinx()\n",
    "axes2.yaxis.set_major_formatter(FuncFormatter(lambda x, pos:\"{:0.0f}\".format(np.square(x))))\n",
    "axes2.set_ylabel(\"Number of comments\")\n",
    "axes2.plot(axes.get_xticks(), data2.values,\n",
    "                   linestyle='-', marker='.', linewidth=.5,\n",
    "                   color='darkgrey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The clearly successful cases, which led to one or more publications, are Polymath 1, 4 and 8.\n",
    "+ Polymath 5 was an indirect success, since elements of it were later used by Terence Tao to prove Erdős’s discrepancy problem.\n",
    "+ The status of Polymath 3 seems unclear, but there important results have been published by a participant to the discussion.\n",
    "+ Polymath 2, 6 and 7 have either been stopped, or seem abandoned.\n",
    "+ Polymath 10 is still active.\n",
    "\n",
    "So far, we can only conclude that unsuccesful project end with only a small number of comments. In some cases this is because it quickly becomes clear that some initial assumptions were false, but in others it is more likely due to a lack of initial progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PROJECTS_TO_C = [\"Mini Polymath {}\".format(i) for i in range(1, 5)]\n",
    "PARTICIPANTS = Series([mPM_FRAME.loc[project]['authors (accumulated)'].iloc[-1] for\n",
    "                project in PROJECTS_TO_C], index=PROJECTS_TO_C)\n",
    "R_NETWORKS = Series([mPM_FRAME.loc[project]['r_network'].dropna().iloc[-1] for project in PROJECTS_TO_C],\n",
    "                    index=PROJECTS_TO_C)\n",
    "WITH_D = [project for project in PROJECTS_TO_C if not mPM_FRAME.loc[project]['research'].all()]\n",
    "D_NETWORKS = Series([mPM_FRAME.loc[project]['d_network'].dropna().iloc[-1] for project in WITH_D],\n",
    "                    index=WITH_D)\n",
    "R_PARTICIPANTS = R_NETWORKS.apply(lambda network: set(network.author_frame.index))\n",
    "D_PARTICIPANTS = D_NETWORKS.apply(lambda network: set(network.author_frame.index))\n",
    "COMMENTS = Series([mPM_FRAME.loc[project]['number of comments (accumulated)'].iloc[-1] for\n",
    "                project in PROJECTS_TO_C], index=PROJECTS_TO_C)\n",
    "\n",
    "df = DataFrame({'all threads': PARTICIPANTS, 'research threads': R_PARTICIPANTS, 'discussion threads': D_PARTICIPANTS},\n",
    "              index=PROJECTS_TO_C)\n",
    "df['authors only active in research threads'] = df['research threads'] - df['discussion threads']\n",
    "df['authors only active in \"discussion\" threads'] = df['discussion threads'] - df['research threads']\n",
    "df['authors active in both types of threads'] = df['all threads'] - df['authors only active in research threads'] - df['authors only active in \"discussion\" threads']\n",
    "for project in PROJECTS_TO_C:\n",
    "    if pd.isnull(df.loc[project]['authors only active in research threads']):\n",
    "        df.loc[project]['authors only active in research threads'] = df.loc[project]['all threads']\n",
    "data = df[['authors only active in research threads', 'authors only active in \"discussion\" threads', 'authors active in both types of threads']]\n",
    "data = data.applymap(lambda set: len(set) if pd.notnull(set) else 0)\n",
    "matplotlib.style.use('seaborn-notebook')\n",
    "axes = data.plot(kind='bar', stacked=True, color=['steelblue', 'lightsteelblue', 'lightgrey'],\n",
    "          title=\"Number of participants per thread-type in each Mini Polymath project\\n Number of comments per thread\")\n",
    "axes.set_ylabel(\"Number of participants\")\n",
    "axes.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "data2 = COMMENTS\n",
    "axes2 = axes.twinx()\n",
    "axes2.set_ylabel(\"Number of comments\")\n",
    "axes2.plot(axes.get_xticks(), data2.values,\n",
    "                   linestyle='-', marker='.', linewidth=.5,\n",
    "                   color='darkgrey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evolution of participants in each project across Polymath and Mini Polymath\n",
    "Our next move is to look at how Polymath evolves as a community.\n",
    "\n",
    "First, we only look at the size of the groups of participants over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_community_evolution(\"Polymaths\")\n",
    "plot_community_evolution(\"MiniPolymaths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals, especially for the main projects, that the group of participants varies considerably over time, and that only a small core remains fixed.\n",
    "\n",
    "Then we look at what remained constant over time in the group of participants. The plots below show for each participant active in at least 3 (Polymath) or 2 (Mini Polymath) projects, in which projects they were active.\n",
    "\n",
    "Apart from the fact that no participant was active in all projects (only `Anonymous`, which was omited from the plots, did better than the trio Gowers, Tao and Kalai), we also see that 22 out of the 29 listed participants were there from the start. A similar pattern can be found in the mini projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_participation_evolution(\"Polymath\", n=3)\n",
    "plot_participation_evolution(\"Mini Polymath\", n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we expand our focus for the Polymath-projects and look at all participants active in at least 2 projects, 33 out of 60 were active from the start. We also see that participation need not be continuous or in consecutive projects. At first sight, it's also not the case that participation in a succesful project leads to particpation in the next project (several participants were active in 4 and 8 but not in between)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_participation_evolution(\"Polymath\", n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Focused comparisons\n",
    "\n",
    "We now compare the structure and evolution of specific projects, and focus on the larger projects Polymath 1, 4 and 8 that led to published results.\n",
    "\n",
    "Recall that the width of the bars corresponds to the number of comments in each thread, and that higher bars signal \"more diverse\" threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_thread_evolution(\"Polymath 1\", compress=140, sel=[0, 1, 15, 19], sharex=True)\n",
    "plot_thread_evolution(\"Polymath 4\", compress=140, sel=[0, 1, 2, 3, 4, 5, 6], sharex=True)\n",
    "plot_thread_evolution(\"Polymath 8\", compress=280, sel=[4, 6, 29], sharex=True)\n",
    "plot_thread_evolution(\"Polymath 10\", compress=140, sel=[0, 1, 2, 3], sharex=True)\n",
    "plot_thread_evolution(\"Polymath 11\", compress=140, sel=[0, 1, 2, 3, 4], sharex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that even in the larger successful projects, active participation goes up and down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_participation_evolution(\"Polymath 1\", n=5)\n",
    "plot_participation_evolution(\"Polymath 4\", n=1)\n",
    "plot_participation_evolution(\"Polymath 8\", n=7)\n",
    "plot_participation_evolution(\"Polymath 10\", n=2)\n",
    "plot_participation_evolution(\"Polymath 11\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_growth('Polymath 4', last=\"2009-09-01\")\n",
    "plot_activity(\"Polymath 4\", last=\"2009-09-01\")\n",
    "#plot_growth('Polymath 7', last=\"2012-07-15\")\n",
    "#plot_growth('Polymath 9', last=\"2013-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_growth('Polymath 10')\n",
    "plot_growth('Polymath 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_network(\"Polymath 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_network(\"Polymath 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activity_degree(\"Polymath 10\")\n",
    "plot_activity_degree(\"Polymath 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activity_pie(\"Polymath 10\")\n",
    "plot_activity_pie(\"Polymath 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM4_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib_venn import venn2, venn3\n",
    "i=12\n",
    "venn2([PM_FRAME.loc[\"Polymath 1\"].iloc[i]['authors'],\n",
    "               PM_FRAME.loc[\"Polymath 1\"].iloc[i+1]['authors']],\n",
    "              set_labels=['Thread {}'.format(i), 'Thread {}'.format(i+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first *pattern* that emerges is that Polymath 1 was indeed special in the following senses:\n",
    "1. It reached more people\n",
    "2. It led to more intense discussions\n",
    "3. It created the core of the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_network(\"Polymath 4\")\n",
    "end_pm4 = get_project_at(\"Polymath 4\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(nx.condensation(end_pm4['network'].graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from itertools import combinations\n",
    "#AUTHOR_SETS = [PM_FRAME.loc[project]['authors (accumulated)'].iloc[-1] for\n",
    "#               project in (\"Polymath {}\".format(i) for i in range(1, 3))]\n",
    "#ALL_LINKS = list(chain.from_iterable(combinations(a_set, 2) for a_set in AUTHOR_SETS))\n",
    "#len(ALL_LINKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for link in ALL_LINKS:\n",
    "#    if not link in BIG_NETWORK.edges():\n",
    "#        BIG_NETWORK.add_edge(*link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ALL_LINKS = (tuple(product(PM_FRAME['authors'].iloc[i], PM_FRAME['authors'].iloc[i])) for i in range(len(PM_FRAME)))\n",
    "#ALL_LINKS = (tuple(product(PM_FRAME['authors'].iloc[i], PM_FRAME['authors'].iloc[i])) for i in range(2))\n",
    "\n",
    "#for links in ALL_LINKS:\n",
    "#    for link in links:\n",
    "#        if not link in BIG_NETWORK.edges():\n",
    "#            BIG_NETWORK.add_edge(*link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#positions = nx.spring_layout(BIG_NETWORK, k=10)\n",
    "#nx.draw_networkx(BIG_NETWORK, positions, with_labels=True)\n",
    "#nx.draw_shell(BIG_NETWORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#k_comps = nx.k_components(BIG_NETWORK)\n",
    "#k_comps.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with the above plots is that there is no way to connect threads to dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_community_engagement(\"Polymath 1\", compress=150, sel=[4, 29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_network(\"Polymath 5\")\n",
    "draw_network(\"Mini Polymath 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activity_pie(\"Polymath 5\")\n",
    "plot_activity_degree(\"Polymath 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing the sizes of the projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_project.sum(axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PM1_AFRAME = PM_FRAME.loc['Polymath 1'].iloc[-1]['network'].author_frame\n",
    "AFRAME = PM1_AFRAME[['word counts', 'total comments', 'replies (all)', 'degree centrality']]\n",
    "pd.scatter_matrix(AFRAME[AFRAME['degree centrality'] != 0], diagonal='kde', color='k', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing projects and mini-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mPM_FRAME['mthread (accumulated)'].iloc[3].plot_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urlparse(\"http://www.logicandinformation.be/index.html\").path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_centre(\"Polymath 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
